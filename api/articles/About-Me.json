{"title":"About Me","slug":"About-Me","date":"2023-04-09T12:38:52.000Z","updated":"2023-05-01T08:19:27.429Z","comments":true,"path":"api/articles/About-Me.json","photos":[],"link":"","excerpt":" [Figure]   Perhaps you would like to know me... ","covers":["/2023/04/09/About-Me/dyf_home.jpeg"],"content":"<img src=\"/2023/04/09/About-Me/dyf_home.jpeg\" class=\"\" title=\"[cover]\">\n\n<center> <font size=\"4\"> Perhaps you would like to know me... </font></center>\n\n<span id=\"more\"></span>\n\n\n\n<hr>\n<p>My name is Dong Yifei. From 2017 to 2021, I obtained a Bachelor’s degree in Mechanical Design, Manufacturing and Automation from Southwest Jiaotong University. During this period, I received comprehensive scholarships and the Merit Student Honor Award every year, and participated in many beneficial competitions and activities.  In 2021, I obtained the recommendation qualification and chose to join <a href=\"http://www.adv-ci.com/blog/\">Professor Bu’s team</a> to work on SLAM and 3D reconstruction related projects. </p>\n<p>Over the past few years, my research interests have primarily focused on the fields of SLAM systems and 3D reconstruction. Currently, I have published three papers (under review) and two invention patents in related fields. My research mainly focuses on multi-sensor fusion SLAM systems and single-image-based 3D reconstruction at a large scale. In the future, I hope to continue researching multi-sensor fusion or deep learning-based SLAM systems and 3D reconstruction technology.</p>\n<p>During my master’s studies, I worked on projects related to SLAM and 3D reconstruction. The details of these projects can be found on my [homepage](During my master’s studies, I worked on projects related to SLAM and 3D reconstruction. The details of these projects can be found on my homepage.).</p>\n<ol>\n<li><p>To overcome the limitations of a single UAV’s flight distance and low reconstruction efficiency in large-scale 3D reconstruction, we proposed a multi-UAV framework for real-time large-scale dense reconstruction and collaborative localization. The framework mainly addresses the following issues: efficient relative positioning and scale unification using coupled GNSS and visual odometry (VO) data, incremental dense point cloud generation, and a centralized collaborative mapping architecture.</p>\n</li>\n<li><p>To address the scale drift and degradation problems in monocular SLAM systems, we proposed a tightly-coupled framework for VO and UWB, which effectively solves the scale ambiguity problem in monocular visual SLAM. This tightly-coupled system addresses the following issues: single anchor point initial pose estimation, joint optimization of visual and UWB observations, and more.</p>\n</li>\n<li><p>In most cases, dense reconstruction from a top-down perspective on a large scale cannot effectively reconstruct the side facades of buildings. To address this problem, we attempted to use a LiDAR sensor to reconstruct the side facades and then fuse them with the visual reconstruction map. The classic ICP algorithm is difficult to achieve accurate matching in this scenario, so we used global descriptors and 2D boundaries for point cloud registration, which ultimately achieved state-of-the-art results.</p>\n</li>\n</ol>\n<p>In my future research, I hope to continue exploring the challenges in the field of robotics, including but not limited to perception and localization of robots. In the field of multi-sensor fusion perception, there are still many urgent problems to be solved, such as the issue of confidence in observation information in multi-sensor fusion, visual and LiDAR fusion modeling, cumulative navigation errors in the event of global sensor failure, and more. For 3D reconstruction, traditional reconstruction methods have limited effectiveness in the absence of significant hardware performance improvements. Combining the idea of NERF with traditional 3D reconstruction methods to achieve real-time 3D reconstruction is a meaningful problem to solve.</p>\n","categories":[],"tags":[]}