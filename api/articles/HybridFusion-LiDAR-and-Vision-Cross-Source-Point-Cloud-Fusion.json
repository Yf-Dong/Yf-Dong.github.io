{"title":"HybridFusion: LiDAR and Vision Cross-Source Point Cloud Fusion","slug":"HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion","date":"2023-04-04T02:26:19.000Z","updated":"2023-04-14T13:17:57.184Z","comments":true,"path":"api/articles/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion.json","photos":[],"link":"","excerpt":" [Figure]   A cross-source point cloud fusion algorithm  which can register cross-source dense point clouds from different viewing angle in outdoor large scenes. ","covers":["/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/example.jpg","/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/pipline.png","/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/equipment.jpeg"],"content":"<img src=\"/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/example.jpg\" class=\"\" title=\"[cover]\">\n\n<center> <font size=\"4\"> A cross-source point cloud fusion algorithm  which can register cross-source dense point clouds from different viewing angle in outdoor large scenes. </font></center>\n\n<span id=\"more\"></span>\n\n<hr>\n<p>Recently, cross-source point cloud registration from different sensors has become a significant research focus. However, traditional methods confront challenges due to the varying density and structure of cross-source point clouds. </p>\n<p>In order to solve these problems, we propose a cross-source point cloud fusion algorithm called HybridFusion. It can register cross-source dense point clouds from different viewing angle in outdoor large scenes.<br>The entire registration process is a coarse-to-fine procedure. First, the point cloud is divided into small patches, and a matching patch set is selected based on global descriptors and spatial distribution, which constitutes the coarse matching process. To achieve fine matching, 2D registration is performed by extracting 2D boundary points from patches, followed by 3D adjustment. Finally, the results of multiple patch pose estimates are clustered and fused to determine the final pose.<br>The proposed approach is evaluated comprehensively through qualitative and quantitative experiments. In order to compare the robustness of cross-source point cloud registration, the proposed method and generalized iterative closest point method are compared. Furthermore, a metric for describing the degree of point cloud filling is proposed. The experimental results demonstrate that our approach achieves state-of-the-art performance in cross-source point cloud registration.</p>\n<img src=\"/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/pipline.png\" class=\"\" title=\"[pipeline]\">\n\n<blockquote>\n<p>System overview of Hybrid Fusion</p>\n</blockquote>\n<img src=\"/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/equipment.jpeg\" class=\"\" title=\"[equipment]\">\n\n<blockquote>\n<p>Equipment of experiments.</p>\n</blockquote>\n<p>Contributions of this work are summarized as follows:</p>\n<ul>\n<li><p>A multi-view cross-source point cloud fusion algorithm is proposed, which can quickly build a complete 3D point cloud.</p>\n</li>\n<li><p>In order to overcome the difference in the spatial distribution of point clouds from different viewings, a point cloud registration method based on the joint optimization of global descriptors and 2D boundary is proposed. This method can effectively fuse cross-source point clouds.</p>\n</li>\n<li><p>A cross-view fusion  <a href=\"https://github.com/npupilab/cvf-dataset\">dataset</a>, including multiple simulation and real-world datasets, is established, which is composed of over-view and street-view data.</p>\n</li>\n</ul>\n<p>The full paper can be found <a href=\"https://arxiv.org/abs/2304.04508\">here</a>.</p>\n<p>The video can be found <a href=\"https://www.bilibili.com/video/BV1vM41147yD/?spm_id_from=333.999.0.0\">here</a>.</p>\n<div style=\"position: relative; width: 100%; height: 50%; padding-bottom: 75%;\"><iframe \nsrc=\"////player.bilibili.com/player.html?aid=525598364&bvid=BV1vM41147yD&cid=1039739475&page=1\" scrolling=\"no\" border=\"0\" \nframeborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; \nheight: 100%; left: 0; top: 0;\"> </iframe></div>\n\n\n","categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]}