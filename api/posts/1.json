{"total":6,"pageSize":10,"pageCount":1,"data":[{"title":"About Me","slug":"About-Me","date":"2023-04-09T12:38:52.000Z","updated":"2023-05-01T08:19:27.429Z","comments":true,"path":"api/articles/About-Me.json","excerpt":"<img src=\"/2023/04/09/About-Me/dyf_home.jpeg\" class=\"\" title=\"[cover]\">\n\n<center> <font size=\"4\"> Perhaps you would like to know me... </font></center>","keywords":null,"cover":"/2023/04/09/About-Me/dyf_home.jpeg","content":null,"text":" [Figure]   Perhaps you would like to know me... My name is Dong Yifei. From 2017 to 2021, I obtained a Bachelorâ€™s degree in Mechanical Desi","link":"","raw":null,"photos":[],"categories":[],"tags":[]},{"title":"ClusterFusion","slug":"ClusterFusion","date":"2023-04-06T13:06:41.000Z","updated":"2023-04-14T13:18:02.572Z","comments":true,"path":"api/articles/ClusterFusion.json","excerpt":"<img src=\"/2023/04/06/ClusterFusion/ClusterFusion_cover.jpg\" class=\"\" title=\"[cover]\">\n\n<center> <font size=\"4\"> A multi-UAV framework for real-time large-scale dense reconstruction and collaborative localization. </font></center>","keywords":null,"cover":"/2023/04/06/ClusterFusion/ClusterFusion_cover.jpg","content":null,"text":" [Figure]  ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]},{"title":"Indoor UAV Autonomous Detection and Tracking System","slug":"Indoor-UAV-Autonomous-Detection-and-Tracking-System","date":"2023-04-06T07:27:04.000Z","updated":"2023-04-14T13:17:44.544Z","comments":true,"path":"api/articles/Indoor-UAV-Autonomous-Detection-and-Tracking-System.json","excerpt":"<img src=\"/2023/04/06/Indoor-UAV-Autonomous-Detection-and-Tracking-System/uav_front.jpeg\" class=\"\" title=\"[cover]\">\n\n<center> <font size=\"4\"> The intelligent autonomous UAS design is carried out in the mission context of cooperative reconnaissance of multiple ground-moving targets in GPS denial environment by performing autonomous positioning, target identification, target tracking and other tasks to achieve accurate identification, continuous tracking and positioning of specific targets. </font></center>\n\n<h5 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h5>","keywords":null,"cover":"/2023/04/06/Indoor-UAV-Autonomous-Detection-and-Tracking-System/uav_front.jpeg","content":null,"text":" [Figure] A description of the software can be found here, but this content is in Chinese.The video can be found here (FIXME).","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Project","slug":"Project","count":2,"path":"api/tags/Project.json"}]},{"title":"UWB-VO: Ultra-wideband Anchor Assisted Visual Odometry","slug":"UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry","date":"2023-04-05T13:17:12.000Z","updated":"2023-04-14T13:17:36.544Z","comments":true,"path":"api/articles/UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry.json","excerpt":"<img src=\"/2023/04/05/UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry/UAV.bmp\" class=\"\" title=\"[cover]\">\t\n\n<center> <font size=\"4\"> A novel tightly coupled simultaneous localization and mapping (SLAM) method that combines monocular vision and ultra-wideband (UWB) technology. </font></center>","keywords":null,"cover":"/2023/04/05/UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry/UAV.bmp","content":null,"text":" [Figure]  ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]},{"title":"HybridFusion: LiDAR and Vision Cross-Source Point Cloud Fusion","slug":"HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion","date":"2023-04-04T02:26:19.000Z","updated":"2023-04-14T13:17:57.184Z","comments":true,"path":"api/articles/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion.json","excerpt":"<img src=\"/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/example.jpg\" class=\"\" title=\"[cover]\">\n\n<center> <font size=\"4\"> A cross-source point cloud fusion algorithm  which can register cross-source dense point clouds from different viewing angle in outdoor large scenes. </font></center>","keywords":null,"cover":"/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/example.jpg","content":null,"text":" [Figure]  ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]},{"title":"Terrain Following in AirSim","slug":"A-Fast-Reconstuction-Method-Based-on-Real-time-Terrain-Following","date":"2023-04-03T13:40:53.000Z","updated":"2023-04-14T13:18:22.127Z","comments":true,"path":"api/articles/A-Fast-Reconstuction-Method-Based-on-Real-time-Terrain-Following.json","excerpt":"<img src=\"/2023/04/03/A-Fast-Reconstuction-Method-Based-on-Real-time-Terrain-Following/fig_top.png\" class=\"\" title=\"[cover]\">\n\n<center> <font size=\"4\"> An algorithm for real-time exploration and reconstruction that does not demand any prior map of the area. </font></center>","keywords":null,"cover":"/2023/04/03/A-Fast-Reconstuction-Method-Based-on-Real-time-Terrain-Following/fig_top.png","content":null,"text":" [Figure] The framework is as above.","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Project","slug":"Project","count":2,"path":"api/tags/Project.json"}]}]}