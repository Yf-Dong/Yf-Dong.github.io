{"total":5,"pageSize":10,"pageCount":1,"data":[{"title":"About Me","slug":"About-Me","date":"2023-04-09T12:38:52.000Z","updated":"2023-04-10T11:16:55.088Z","comments":true,"path":"api/articles/About-Me.json","excerpt":"<img src=\"/2023/04/09/About-Me/dyf_home.jpeg\" class=\"\" title=\"[cover]\">\n\n<center> <font size=\"5\" color=\"blue\"> Perhaps you would like to know me... </font></center>","keywords":null,"cover":"/2023/04/09/About-Me/dyf_home.jpeg","content":null,"text":" [Figure]   Perhaps you would like to know me... My name is Dong Yifei. From 2017 to 2021, I obtained a Bachelorâ€™s degree in Mechanical Desi","link":"","raw":null,"photos":[],"categories":[],"tags":[]},{"title":"ClusterFusion","slug":"ClusterFusion","date":"2023-04-06T13:06:41.000Z","updated":"2023-04-10T11:01:44.101Z","comments":true,"path":"api/articles/ClusterFusion.json","excerpt":"<img src=\"/2023/04/06/ClusterFusion/ClusterFusion_cover.jpg\" class=\"\" title=\"[cover]\">\n\n<h4 id=\"A-cluster-framework-for-real-time-large-scale-dense-reconstruction-and-collaborative-localization\"><a href=\"#A-cluster-framework-for-real-time-large-scale-dense-reconstruction-and-collaborative-localization\" class=\"headerlink\" title=\"A cluster framework for real-time large-scale dense reconstruction and  collaborative localization.\"></a><em>A cluster framework for real-time large-scale dense reconstruction and  collaborative localization.</em></h4>","keywords":null,"cover":"/2023/04/06/ClusterFusion/ClusterFusion_cover.jpg","content":null,"text":" [Figure]  ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]},{"title":"Indoor UAV Autonomous Detection and Tracking System","slug":"Indoor-UAV-Autonomous-Detection-and-Tracking-System","date":"2023-04-06T07:27:04.000Z","updated":"2023-04-10T11:04:20.628Z","comments":true,"path":"api/articles/Indoor-UAV-Autonomous-Detection-and-Tracking-System.json","excerpt":"<img src=\"/2023/04/06/Indoor-UAV-Autonomous-Detection-and-Tracking-System/uav_front.jpeg\" class=\"\" title=\"[cover]\">\n\n\n\n<h4 id=\"The-intelligent-autonomous-UAS-design-is-carried-out-in-the-mission-context-of-cooperative-reconnaissance-of-multiple-ground-moving-targets-in-GPS-denial-environment-by-performing-autonomous-positioning-target-identification-target-tracking-and-other-tasks-to-achieve-accurate-identification-continuous-tracking-and-positioning-of-specific-targets\"><a href=\"#The-intelligent-autonomous-UAS-design-is-carried-out-in-the-mission-context-of-cooperative-reconnaissance-of-multiple-ground-moving-targets-in-GPS-denial-environment-by-performing-autonomous-positioning-target-identification-target-tracking-and-other-tasks-to-achieve-accurate-identification-continuous-tracking-and-positioning-of-specific-targets\" class=\"headerlink\" title=\"The intelligent autonomous UAS design is carried out in the mission context of cooperative reconnaissance of multiple ground-moving targets in GPS denial environment by performing autonomous positioning, target identification, target tracking and other tasks to achieve accurate identification, continuous tracking and positioning of specific targets.\"></a><em>The intelligent autonomous UAS design is carried out in the mission context of cooperative reconnaissance of multiple ground-moving targets in GPS denial environment by performing autonomous positioning, target identification, target tracking and other tasks to achieve accurate identification, continuous tracking and positioning of specific targets.</em></h4>","keywords":null,"cover":"/2023/04/06/Indoor-UAV-Autonomous-Detection-and-Tracking-System/uav_front.jpeg","content":null,"text":" [Figure] A description of the software can be found here, but this content is in Chinese.The video can be found here (FIXME).","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Project","slug":"Project","count":1,"path":"api/tags/Project.json"}]},{"title":"UWB-VO: Ultra-wideband Anchor Assisted Visual Odometry","slug":"UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry","date":"2023-04-05T13:17:12.000Z","updated":"2023-04-10T11:01:58.506Z","comments":true,"path":"api/articles/UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry.json","excerpt":"<img src=\"/2023/04/05/UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry/UAV.bmp\" class=\"\" title=\"[cover]\">\t\n\n<h4 id=\"A-novel-tightly-coupled-simultaneous-localization-and-mapping-SLAM-method-that-combines-monocular-vision-and-ultra-wideband-UWB-technology\"><a href=\"#A-novel-tightly-coupled-simultaneous-localization-and-mapping-SLAM-method-that-combines-monocular-vision-and-ultra-wideband-UWB-technology\" class=\"headerlink\" title=\"A novel tightly coupled simultaneous localization and mapping (SLAM) method that combines monocular vision and ultra-wideband (UWB) technology.\"></a><em>A novel tightly coupled simultaneous localization and mapping (SLAM) method that combines monocular vision and ultra-wideband (UWB) technology.</em></h4>","keywords":null,"cover":"/2023/04/05/UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry/UAV.bmp","content":null,"text":" [Figure]  ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]},{"title":"HybridFusion: LiDAR and Vision Cross-Source Point Cloud Fusion","slug":"HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion","date":"2023-04-04T02:26:19.000Z","updated":"2023-04-10T11:02:07.224Z","comments":true,"path":"api/articles/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion.json","excerpt":"<img src=\"/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/example.jpg\" class=\"\" title=\"[cover]\">\n\n<h4 id=\"A-cross-source-point-cloud-fusion-algorithm-which-can-register-cross-source-dense-point-clouds-from-different-viewing-angle-in-outdoor-large-scenes\"><a href=\"#A-cross-source-point-cloud-fusion-algorithm-which-can-register-cross-source-dense-point-clouds-from-different-viewing-angle-in-outdoor-large-scenes\" class=\"headerlink\" title=\"A cross-source point cloud fusion algorithm  which can register cross-source dense point clouds from different viewing angle in outdoor large scenes.\"></a><em>A cross-source point cloud fusion algorithm  which can register cross-source dense point clouds from different viewing angle in outdoor large scenes.</em></h4>","keywords":null,"cover":"/2023/04/04/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/example.jpg","content":null,"text":" [Figure]  ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]}]}