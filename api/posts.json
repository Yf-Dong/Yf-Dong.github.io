{"total":5,"pageSize":10,"pageCount":1,"data":[{"title":"HybridFusion: LiDAR and Vision Cross-Source Point Cloud Fusion","slug":"HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion","date":"2023-04-06T02:26:19.000Z","updated":"2023-04-06T02:52:28.851Z","comments":true,"path":"api/articles/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion.json","excerpt":"<img src=\"/2023/04/06/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/example.jpg\" class=\"\" title=\"[cover]\">\n\n<p>Recently, cross-source point cloud registration from different sensors has become a significant research focus. However, traditional methods confront challenges due to the varying density and structure of cross-source point clouds. </p>","keywords":null,"cover":"/2023/04/06/HybridFusion-LiDAR-and-Vision-Cross-Source-Point-Cloud-Fusion/example.jpg","content":null,"text":" [Figure]  ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]},{"title":"UWB-VO: Ultra-wideband Anchor Assisted Visual Odometry","slug":"UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry","date":"2023-04-05T13:17:12.000Z","updated":"2023-04-05T15:02:50.692Z","comments":true,"path":"api/articles/UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry.json","excerpt":"<img src=\"/2023/04/05/UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry/UAV.bmp\" class=\"\" title=\"[cover]\">\t\n\n<p>â€‹\tThis paper proposes a novel tightly coupled simultaneous localization and mapping (SLAM) method that combines monocular vision and ultra-wideband (UWB) technology. The proposed approach utilizes UWB distance information to restore the scale of monocular SLAM with an error rate of less than 1%. Our approach joint optimizes the distance residual between the camera and anchor, and the reprojection error of the map point, to improve SLAM positioning accuracy and mitigate visual SLAM degradation in challenging environments. A novel UWB anchor position optimization method is proposed, which enables the system to complete initialization within 2 seconds. The experimental results show that the proposed fusion scheme achieves significantly higher accuracy in system scale estimation and positioning compared to current state-of-the-art SLAM and visual-inertial odometry algorithms.</p>","keywords":null,"cover":"/2023/04/05/UWB-VO-Ultra-wideband-Anchor-Assisted-Visual-Odometry/UAV.bmp","content":null,"text":" [Figure]  ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]},{"title":"Indoor UAV Autonomous Detection and Tracking System","slug":"Indoor-UAV-Autonomous-Detection-and-Tracking-System","date":"2023-04-05T07:27:04.000Z","updated":"2023-04-05T08:59:09.493Z","comments":true,"path":"api/articles/Indoor-UAV-Autonomous-Detection-and-Tracking-System.json","excerpt":"<p>The intelligent autonomous UAS design is carried out in the mission context of cooperative reconnaissance of multiple ground-moving targets in GPS denial environment by performing autonomous positioning, target identification, target tracking and other tasks to achieve accurate identification, continuous tracking and positioning of specific targets. </p>\n<img src=\"/2023/04/05/Indoor-UAV-Autonomous-Detection-and-Tracking-System/uav_front.jpeg\" class=\"\" title=\"[cover]\">","keywords":null,"cover":"/2023/04/05/Indoor-UAV-Autonomous-Detection-and-Tracking-System/uav_front.jpeg","content":null,"text":"The intelligent autonomous UAS design is carried out in the mission context of cooperative reconnaissance of multiple ground-moving targets ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Project","slug":"Project","count":1,"path":"api/tags/Project.json"}]},{"title":"ClusterFusion","slug":"ClusterFusion","date":"2023-04-03T13:06:41.000Z","updated":"2023-04-06T02:49:59.899Z","comments":true,"path":"api/articles/ClusterFusion.json","excerpt":"<img src=\"/2023/04/03/ClusterFusion/ClusterFusion_cover.jpg\" class=\"\" title=\"[cover]\">\n\n<p>As robotics technology advances, dense point cloud maps are increasingly in demand. However, dense reconstruction using a single unmanned aerial vehicle (UAV) suffers from limitations in flight speed and battery power, resulting in slow reconstruction and low coverage. Cluster UAV systems offer greater flexibility and wider coverage for map building. Existing methods of cluster UAVs face challenges with accurate relative positioning, scale drift, and high-speed dense point cloud map generation. </p>","keywords":null,"cover":"/2023/04/03/ClusterFusion/ClusterFusion_cover.jpg","content":null,"text":" [Figure]  ","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"Paper","slug":"Paper","count":3,"path":"api/tags/Paper.json"}]},{"title":"Hello World","slug":"hello-world","date":"2023-03-31T12:01:54.224Z","updated":"2023-04-03T12:52:07.317Z","comments":true,"path":"api/articles/hello-world.json","excerpt":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>","keywords":null,"cover":null,"content":null,"text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the ","link":"","raw":null,"photos":[],"categories":[],"tags":[]}]}